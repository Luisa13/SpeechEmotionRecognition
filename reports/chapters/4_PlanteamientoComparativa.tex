\documentclass[11pt,a4paper,spanish]{book}
\usepackage{biblatex}
\usepackage[utf8]{inputenc}
% Imagenes
\usepackage{graphicx, wrapfig, lipsum}
\graphicspath{ {./.images/} }
\usepackage{float}
\usepackage{comment}
\addbibresource{./bibLib/mycol_arte.bib}


\begin{document}
	\chapter{Planteamiento de la comparativa}
	
	En este capítulo se identificará el problema en concreto a tratar, a la vez que el diseño de los experimentos para acometerlo. Para ello se exponen los datos utilizados así como un análisis en detalle de estos respondiendo a por qué se escogen esos conjuntos. Finalmente las técnicas de procesamiento y el diseño de la red neuronal propuesta que se usan en este trabajo
	
	El objetivo de esta comparativa es contrastar los resultados obtenidos tras aplicar el mismo sistema de reconocimiento de emociones en la voz entrenado con un lenguaje de referencia, con los otros dos lenguajes escogidos. Mediante esta comparativa se pretende responder a la pregunta si es posible reconocer emociones en un idioma que en principio se desconoce.
	
	\section{Conjunto de Datos}
	\label{lb_c4_datos}
	Los datos en un proyecto de inteligencia artificial son clave, de cara a la obtención de un resultado coherente en nuestro trabajo. Este estudio pretende analizar si es posible clasificar emociones en la lengua extranjera y para encontrar una respuesta, se seguirá la siguiente estrategia con respecto a los datos.
	
	\paragraph{Idioma de referencia: Inglés} El idioma de referencia será el cuál aprenda nuestra red neuronal, y desde el cual se intenten reconocer emociones en otras lenguas. En este caso se propone el inglés.\\
	
	El conjunto de datos que se usará para el idioma de referencia, será La Base de Datos Audiovisual del Discurso y Canción Emocional RAVDESS (por sus siglas en inglés \emph{Ryerson Audio-Visual Database of Emotional Speech and Song}), el cual contiene 7356 archivos en total, entre los cuales podemos encontrar 3 modalidades: sólo audio (en 16 bit, 48 kHz y en formato wav), audio-video (720p H.264, AAC 48kHz, en formato mp4) y sólo video sin sonido. Esta base de datos contiene 24 actores profesionales vocalizando dos frases en inglés norte americano (\emph{Kids are talking by the door} y \emph{Dogs are sitting by the door}).
	
	Cada uno de estos archivos están nombrados de manera única mediante 7 números a modo de descripción de las características del audio. Éste respeta la siguiente convención:
	\begin{itemize}
		\item Modalidad (01 Audio y vídeo, 02 Sólo vídeo, 03 Sólo audio)
		\item Canal vocal (01 discurso normal, 02 canción)
		\item Emoción que representa
		\item Intensidad Emocional Si es normal o fuerte. La voz neutral no contempla la intensidad fuerte.
		\item Repetición (si es la primera repetición 01, si es la segunda 02)
		\item Actor que ejecuta la acción
	\end{itemize}

	Así por ejemplo, el archivo 03-01-03-01-01-01-01.wav dirá que es un archivo de sólo audio (03), donde se vocaliza una frase de manera hablada (01) y con tono alegre (03). La intensidad es normal (01), corresponde a la primera repetición (01) y el actor que la ejecuta es el n.01.
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.35]{ravdess_distribucion.png} 
		\caption{Distribución de las emociones en RAVDESS}
		\label{fig:emociones_ravdess}
	\end{figure}
	
	Como se puede apreciar en la figura \ref{fig:emociones_ravdess} las emociones están regularmente distribuidas, sin embargo, a pesar de que en este dataset hay 7356 muestras, para este proyecto sólo podremos usar los que presentan una modalidad de sólo audio, lo que nos deja con un total de 1440 muestras. 

	
	\paragraph{Idioma con raíces fonéticas similares: Alemán} Este conjunto de datos pertenecerá a un idioma con unas raíces similares al idioma de referencia, de manera que se espera a priori que se puedan reconocer la mayoría de las emociones.\\
	
	Para este caso el conjunto de datos propuesto es la Base de Datos del Discurso Emocional de Berlín (EMODB, por sus siglas en inglés \emph{Berlin Database of Emotional Speech}). Este corpus contiene 800 grabaciones interpretadas por 10 actores (5 hombres y 5 mujeres) modulando 7 emociones en el idioma alemán. Como en el anterior, se utiliza una nomenclatura para nombrar a los archivos que satisface lo siguiente:
	\begin{itemize}
		\item Las dos primeras posiciones determinan el actor que las interpreta.
		\item De la posición 3 a las 5 se define el texto que se pronuncia
		\item La posición 6 indica la emoción.
		\item Versión del audio en caso de que la hubiese (codificado con letras).
	\end{itemize}

	Como ejemplo, el archivo \emph{03a01Fa.wav} indica que el actor 03 (hombre de 31 años) cita el texto a01 (\emph{Der Lappen liegt auf dem Eisschrank}, en alemán "El mantel está colgando del frigo"), con la emoción F (felicidad), y es la versión \emph{a} (la primera).
	
	La documentación del corpus también nos ofrece información sobre el género y edad de los actores, lo cual se ha determinado irrelevante, y las distintas frases que pueden aparecer en los archivos.
	Las emociones que clasifica son enfado (W), aburrimiento (L), asco (E), miedo o ansiedad (A), felicidad (F), tristeza (T) y neutral (N) codificadas en el nombre del archivo por su inicial en alemán (especificada entre paréntesis).


	
	\paragraph{Idioma con raíces fonéticas distintas} Este conjunto de datos pertenecerá a un idioma con unas raíces más distantes al idioma de referencia.\\
	
	
	\section{Extracción de características}
	Teniendo en cuenta el previo estudio de la literatura en el capítulo 2, se concluye que los métodos más prometedores, y que por lo tanto merecen la pena aplicar a este estudio comparativo serían los siguientes:
	\subsubsection{Coeficientes Cepstrales en la escala de Mel}
	Como ya hemos mencionado, MFCC es uno de los mejores algoritmos para capturar características de la señal de audio debido a su similitud a como el sistema auditivo humano procesa el sonido y las frecuencias, así mismo, su efectividad se ha visto reportada y discutida a lo largo de otros estudios.
	La librería usada para la manipulación de audio Librosa ofrece la posibilidad de extraer características MFCC de un archivo de audio. En cuanto a la configuración, se extraerán 13 características MFCC usando el rango de muestreo propio del archivo de audio.

	\begin{comment}
	Razon por el numero de características:
	https://dsp.stackexchange.com/questions/28898/mfcc-significance-of-number-of-features
		Mencionar que otros estudios
	\end{comment}
	
%	\paragraph{Espectogramas de Mel}
%	La escala de Mel transforma  frecuencias lineales a una escala logarítmica
	
	\section{Pre-procesado de los datos}
	Como se ha visto en la sección \ref{lb_c4_datos} no hay una abundante disposición de datos, esto podría convertirse en un problema y perjudicar el rendimiento del modelo en el entrenamiento. 
	Será necesario, antes del entrenamiento, un previo procesado de los datos.
	
	\subsection{División de los datos por género}
	En un primer análisis exploratorio de los datos, se han estudiado las diferencias entre la voz masculina y la voz femenina en las emociones, observando lo siguiente:
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.35]{comparative_waveform.png} 
		\caption{Comparativa de los extractos de voz por género en RAVDESS}
		\label{fig:comp_emociones_genero}
	\end{figure}
	En la figura \ref{fig:comp_emociones_genero} podemos ver la comparación de la voz masculina (naranja) y la voz femenina (azul) por cada una de las emociones en el idioma inglés. Ya que es muy distinto, puede ser recomendable dividir el conjunto de datos atendiendo a esta característica.
	
	
	%\subsection{Conversión de la señal a imagen}
	% quiza no sea necesario
	
	\subsection{Configuración y normalización de los datos}
	En esta sub-sección se muestra los recursos a los que se ha accedido para el desarrollo del estudio, así como su correspondiente configuración.
\begin{comment}
		\begin{wrapfigure}{l}{0.40\textwidth}
		\vspace{-20pt}
		\centering
		\includegraphics[width=0.4\linewidth]{/logos/colab_icon.png} 
		\vspace{-20pt}
		\end{wrapfigure}
\end{comment}


	\paragraph{Google Colab} Para la exploración de los datos así como el desarrollo, y entrenamiento de los modelos se ha hecho uso de la plataforma gratuita desarrollada por Google, Google Colab. Esta plataforma ofrece 12GB de RAM  y 107.77 espacio en disco, que será más que suficiente dado el tamaño que nuestro dataset.
	
	\paragraph{Librosa 0.8.1} Librosa es un paquete que ofrece diversas funcionalidades para el análisis de audio y música, cuya información más en detalle se puede encontrar en \cite{librosa082}
	
	\paragraph{Tensorflow 2.0} Es una plataforma de código abierto que provee un conjunto de librerías y recursos para el desarrollo de modelos con aprendizaje automático
	
	\paragraph{Python 3} Todo el código para este proyecto ha sido desarrollado en python 3.
	
	\subsection{Ténicas de aumento de datos}
	Dado el bajo número de muestras en los distintos conjuntos de datos a los que hemos podido acceder, se ha visto conveniente explorar distintas técnicas de aumento de datos. El aumento de datos es una técnica por la cual, se aumenta el número de muestras en un conjunto mediante la creación de nuevas muestras sintéticas con pequeñas modificaciones a cada uno de los archivos. Esta aumento de los datos se puede traducir por una reducción del overfitting (sobreajuste), ya que el modelo se mantendría invariable mejorando así su capacidad de generalización.
	Esta técnica es ampliamente conocida cuando se procesan imágenes, siendo esas modificaciones rotaciones, transposiciones etc. En nuestro caso, debemos alterar la señal de audio, modificando la frecuencia, añadiendo ruido...
	
	
		\subsubsection{White Noise o Ruido Blanco}
		Añade ruido blanco a la pista de audio, mediante la inyección de valores aleatorios a la señal.
		
		\subsubsection{Shiftting o Desplazamiento del sonido}
		Desplaza el sonido hacia la izquierda o la derecha una cantidad aleatoria de segundos.
		
		\subsubsection{Pitch Tunning}
		Cambia el tono de la señal de audio de manera aleatoria.
		
	\section{Arquitectura}
	Como se ha podido ver en la revisión de la literatura del capítulo 2, las redes convolucionales esta una tendencia muy adoptada en los últimos trabajos en esta área de estudio.
	Por temas de tiempo blablabla [...] se ha decidido por una red base que reporte buenos resultados
	\section{Criterios de éxito}
	\section{Configuración}
	Aquí hablo de aspectos técnicos, configuración y diseño de los experimentos
	
	
		\printbibliography
	
\end{document}