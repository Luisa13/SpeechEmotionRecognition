\documentclass[11pt,a4paper,spanish]{book}
\usepackage{biblatex}
\usepackage[utf8]{inputenc}
% Para el formato del titulo
\usepackage{titlesec}

\titleformat{\chapter}[block]
{\normalfont\huge\bfseries}{\thechapter.}{1em}{\Huge}
\titlespacing*{\chapter}{0pt}{-19pt}{0pt}
	
% Imagenes
\usepackage{graphicx, wrapfig, hyperref}
\graphicspath{ {./.images/} }
\usepackage{float}
\usepackage{comment}
\addbibresource{./bibLib/mycol_arte.bib}
\setcounter{secnumdepth}{3}

\begin{document}
	\chapter{Desarrollo de la comparativa}
	Las primeras dos pruebas no son muy interesantes desde el punto de vista de una conclusión final, pero ayuda a entender el punto de partida y la progresión de las pruebas, por eso se omite la estructura que si se muestra en las pruebas posteriores.
	\section{Búsqueda de un  modelo óptimo}
	\label{cap:4ModeloOptimo}
	%TODO: hablar de cifras, poner las graficas etc etc
		\subsection{Pruebas 1 y 1.B}
		Ya que la mayoría de los estudios hacían uso de de conjuntos de datos con acceso privado, el objetivo de esta prueba era saber cómo se comportaba un primer enfoque de una arquitectura basada en CNN unidimensional en la base de datos RAVDESS. Tal y como se comentó en la sección \ref{cap4:division}, se tomó la decisión de dividir el dataset por género, ya que se observaban claras diferencias en una muestra aleatoria que comparaba la variaciones de la onda acústica por cada una de las emociones (ver \ref{fig:comp_emociones_genero}). En un primer momento, la inspiración para la arquitectura fue tomada del trabajo de \cite{blabla} pero después de varias pruebas el mejor resultado obtenido fue un 50\% de \emph{accuracy} en la subdivisión para el género femenino y un 31\% para el másculino, mientras que se obtuvo un 38.3\% usando el conjunto completo. El entrenamiento se realizó durante 100 épocas y se quedaba estancado pasado el 30\% de accuracy. Analizando los resultados se observó que, la magnitud de los datos usados en las pruebas podría ser insuficiente teniendo en cuenta el número de clases entre las que se quería distinguir, por lo que se decidió probar con técnicas de aumento de datos.
	
	%50\% accuracy con 720 muestras & 31\%  accuracy con 720 muestras & 38.3 \% accuracy con 1440 muestras \\
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{|p{4.75cm} |p{4.75cm} |p{4.75cm}|}
				\hline
				Ruido blanco & Desplazamiento & Modulación del tono \\ 
				\hline
				\includegraphics[scale=0.15]{tests1_2/female_plot.png} & \includegraphics[scale=0.15]{tests1_2/male_plot.png} & \includegraphics[scale=0.15]{tests1_2/all_data_plot.png}\\
				\hline
				50\% accuracy con 720 muestras & 31\%  accuracy con 720 muestras & 38.3 \% accuracy con 1440 muestras \\
				\hline	
			\end{tabular}
			\caption{Resultados obtenidos tras aplicar aumento de datos}
			\label{cap5:genderplots}
		\end{center}
	\end{table}
	

	\subsection{Pruebas 2 y 2.B} %Data Augmentation
	Debido a los pobres resultados conseguidos en la Prueba 1, en la prueba 2 se decidió contar con el conjunto de datos completo para aplicar técnicas de aumento de datos con el fin de aumentar el número de muestras. Si bien los frutos de esta prueba no arrojaron unos resultados satisfactorios, condujeron a una sólida reducción del overfitting.
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c | c | c |}
				\hline
				Ruido blanco & Desplazamiento & Modulación del tono \\ 
				\hline
				\includegraphics[scale=0.15]{tests1_2/whitenoise.png} & \includegraphics[scale=0.15]{tests1_2/desplazamiento.png} & \includegraphics[scale=0.15]{tests1_2/modulacion.png}\\
				\hline
				50\% accuracy  & 44\%  accuracy & 45\% accuracy \\
				\hline	
			\end{tabular}
			\caption{Resultados obtenidos tras aplicar aumento de datos}
			%\label{}
		\end{center}
	\end{table}
	En la Prueba 2.B, se procedió entonces a combinar los diferentes métodos de aumento de datos. El modelo usado para estas pruebas se entreno durante 1000 épocas con un tamaño del batch de 16
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{|p{4.75cm} |p{4.75cm} |p{4.75cm}|}
				\hline
				Ruido blanco y Desplazamiento& Desplazamiento y Modulación & Ruido blanco, Desplazamiento y Modulación del tono \\ 
				\hline
				\includegraphics[scale=0.15]{tests1_2/wn_despl.png} & \includegraphics[scale=0.15]{tests1_2/mod_desp.png} & \includegraphics[scale=0.15]{tests1_2/todas.png}\\
				\hline
				45.02\% accuracy & 39.76\%  accuracy & 40.03\% accuracy \\
				\hline	
			\end{tabular}
			\caption{Resultados obtenidos tras aplicar aumento de datos}
			%\label{}
		\end{center}
	\end{table}
	
	\subsection{Pruebas 3 y 3.B} %Ensamblado de datasets
	A pesar de que en las pruebas anteriores, no se ha llegado a unos resultados satisfactorios, parece claro que el aumento del conjunto de datos es la dirección por la que apostar, ya que ha reducido notablemente el sobre ajuste que presentaban las primeras pruebas. No obstante, observamos que hasta ahora hemos venido usando la base de datos RAVDESS con 1440 instancias para una clasificación de 8 categorías. Recordemos que por la revisión del estado del arte (ver tabla \ref{tab:metod_comp}), sabemos que \cite{Mustaqeem2020} llega al 81.01\% de accuracy en RAVDESS con una red CNN bidimensional y haciendo una selección de 5 clases. Este conjunto de datos, únicamente contempla 2 tipos de frases, por lo que el bajo rendimiento puede deberse a la poca diversidad de los datos. 
	El objetivo de esta prueba es experimentar un enfoque distinto para aumentar el número de elementos con los que la red entrenará: Un ensamblado de conjuntos de datos en el mismo idioma, aportando una mayor diversidad a los datos, y más capacidad de aprendizaje a la red.
	\paragraph{Datos y preprocesado} En las tres versiones de la prueba 3, se procedió a crear diferentes combinaciones de los datasets, una vez se extrajeron las características MFCC: En un primer lugar se juntaron RAVDESS y TESS dejando un total de 4240 muestras, por otro lado TESS y SAVEE con 3284, y finalmente la combinación de los tres RAVDESS, TESS y SAVEE con 4720 características. La figura \ref{ref:balanceTest3} nos muestra el balance de la distribución de las clases en cada uno de los conjuntos contruidos, y como podemos ver, están bien balanceados.
	\begin{table}[H]
		\centering
		\begin{center}
			
				\begin{tabular}{ c  c | c  c |c  c }
					RAVDESS y &TESS & TESS y &SAVEE & RAVDESS, &TESS y SAVEE \\
					\hline
					asco 		& 592 & asco 		& 460 & asco 		& 652\\
					felicidad 	& 592 & felicidad 	& 460 & felicidad 	& 652\\
					sorpresa 	& 592 & sorpresa 	& 460 & sorpresa 	& 652\\
					tristeza 	& 592 & tristeza 	& 460 & tristeza 	& 652\\
					miedo 		& 592 & miedo 		& 460 & miedo 		& 652\\
					enfado 		& 592 & enfado 		& 460 & enfado 		& 652\\
					neutral 	& 496 & neutral 	& 524 & neutral 	& 616\\
					\hline
				\end{tabular}
				
			\caption{Balance entre las clases de las diferentes combinaciones (sin data augmentation)}
			\label{ref:balanceTest3}
		\end{center}
	\end{table}

	\paragraph{Entrenamiento}
	El entrenamiento de los tres modelos los diferentes conjuntos (tanto en la Prueba 3 como en la 3.B), siguió la misma estrategia, ya que el objetivo era obtener mayor accuracy mediante el incremento de muestras. Se consiguió una notable mejoría en comparación a las pruebas anteriores, alcanzando niveles similares a los que reporta la literatura.
	Paradójicamente, el que peores resultados logró fue la combinación con mayor número de características RAVEE, TESS y SAVEE con 4720 como vemos en la figura \ref{fig:accuTest3_A}.
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c | c | c | c | c | c |}
				\hline
				RAVDESS y TESS & TESS y SAVEE & RAVDESS, TESS y SAVEE \\ 
				\hline
				\includegraphics[scale=0.15]{tests3/ravdess_tess.png} & \includegraphics[scale=0.15]{tests3/tess_savee_1cnn.png} & \includegraphics[scale=0.15]{tests3/ravdess_tess_savee.png}\\
				\hline
				
				73.22\% accuracy & 84.39\%  accuracy & 66.96\% accuracy \\
				\hline	
			\end{tabular}
			\caption{Prueba 3: Resultados tras ensamblar distintos datasets sin aumento de datos}
			\label{fig:accuTest3_A}
		\end{center}
	\end{table}
	
	El uso de la técnica de aumento de datos, no arrojó una mejoría significativa como podemos comparar en la figura \ref{fig:accuTest3_B} (si acaso, una levísima reducción del overfitting).

	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c | c | c | c | c | c |}
				\hline
				RAVDESS y TESS & TESS y SAVEE & RAVDESS, TESS y SAVEE \\ 
				\hline
				\includegraphics[scale=0.15]{tests3/ravdess_tessTest3_A.png} & 
				\includegraphics[scale=0.15]{tests3/savee_tessTest3_A.png} & 
				\includegraphics[scale=0.15]{tests3/ravdess_tess_savee_Aug.png}\\
				\hline
				
				73.07\% accuracy & 84.32\%  accuracy & 81.52\% accuracy \\
				\hline	
			\end{tabular}
			\caption{Prueba 3.B: Resultados tras ensamblar distintos datasets con aumento de datos}
			\label{fig:accuTest3_B}
		\end{center}
	\end{table}

	\paragraph{Evaluación}
	Aunque hay margen de mejora, cabe resaltar el avance con respecto a las otras pruebas, y los resultados sugieren que la diversidad de datos es lo que conlleva un mejor rendimiento del modelo. En la prueba 3 (ya que los resultados de las tres opciones fueron proporcionales, en esta descripción se usa como referencia la subprueba con TESS y SAVEE, y a continuación se provee la tabla \ref{result_Test3} con los resultados de cada una de las combinaciones de esta prueba):
	
	\begin{itemize}
		\item En las tres opciones, se mantuvo que el enfado fue el más difícil de distiguir: En TESS y SAVEE, su precisión fue tan sólo de 38\% mientras que el F1 subió hasta 55\%.
		
		\item El asco, el miedo, la tristeza y la neutralidad, se mantuvieron en un 100\% de precisión, pero su F1 fue de 87\% 87\% 90\% y 85\% respectivamente.
		
		\item La felicidad llegó 99\% de precisión pero su F1 fue de 78\%.
		
		\item La sorpresa finalmente también llegó al 99\% de precisión como la felicidad, pero su F1 se quedó en el 79\%.
	\end{itemize}

	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c|| c c |  c c |  c c | }
				\hline
					\multicolumn{1}{|c||}{Emoción} & 
					\multicolumn{2}{|c|}{RAVDES y SAVEE}&
					\multicolumn{2}{|c|}{TESS y SAVEE} &
					\multicolumn{2}{|c|}{RAVDES, TESS y SAVEE} \\
				\hline
				 	& 
					 \multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}&
					 \multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}&
					 \multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}\\
				\hline

				asco 		& 1.00 & 0.68 & 1.00 & 0.87 & 1.00 & 0.59\\
				felicidad 	& 1.00 & 0.67 & 0.99 & 0.78 & 1.00 & 0.62\\
				sorpresa 	& 1.00 & 0.44 & 0.99 & 0.79 & 1.00 & 0.47\\
				tristeza 	& 0.99 & 0.77 & 1.00 & 0.90 & 1.00 & 0.76\\
				miedo 		& 0.99 & 0.81 & 1.00 & 0.87 & 0.98 & 0.70\\
				enfado 		& 0.28 & 0.44 & 0.38 & 0.55 & 0.25 & 0.40\\
				neutral 	& 1.00 & 0.88 & 1.00 & 0.85 & 1.00 & 0.76\\
				\hline
			\end{tabular}
			
			\caption{Resultado de la evaluación en cada una de las combinaciones de conjuntos de datos}
			\label{result_Test3}
		\end{center}
	\end{table}
	
	
	\subsection{Pruebas 4 y 5}
	El objetivo de estas pruebas es experimentar el uso de los espectrogramas como entrada la red. Por una lado una red CNN bidimensional inspirada en el trabajo de \cite{Mustaqeem2020}, y por otro una arquitectura dual CNN y LSTM. Para no extender esta sección más de lo necesario, y teniendo en cuenta que el objetivo de tener un modelo preciso es poder testearlo con otros idiomas, se ha escogido el mejor resultado de la prueba anterior.
	%TODO: corregir y asegurarte de las dimensiones
	\paragraph{Datos y preprocesado}
	Este paso fue el mismo en ambas pruebas, la extracción de características  se llevó a cabo con el paquete Librosa, y después se procedió a generar los espectogramas. Se leyeron un total de 3284 imágenes, las cuales se recortaron con unas dimensiones de 30 x 40 píxeles.
	
	\subsubsection{Prueba 4}
	\paragraph{Entrenamiento}
	El modelo escogido para esta prueba (una red convolucional bidimensional) se entrenó durante 100 épocas con un batch de tamaño 32, llegando a un 91.10\% de precisión como vemos en la figura \ref{fig:cnn2d}. 
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.35]{test4_5/savee_tess_cnn2d.png} 
		\caption{Rendimiento del modelo CNN usando los datos de SAVEE y TESS}
		\label{fig:cnn2d}
	\end{figure}

	Vemos que el modelo alcanza valores altos en una época temprana (en la \emph{epoch} 3  pasa de un 66\% de precisión en test a un 80\%), y se estabiliza en torno a la época 50 (90\% - 91\%).
	
	\paragraph{Evaluación}
	Esta prueba supuso una sólida mejora en comparación a las pruebas anteriores, ya que los resultados fueron bastante satisfactorios. En la tabla \ref{result_Test4} podemos ver la capacidad del modelo para reconocer cada clase, observando que en concordancia con los resultados obtenidos hasta ahora, el enfado es la que menos puntúa, mientras que la tristeza la que es más fácil de reconocer.
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c|| c c | }
				\hline
				\multicolumn{1}{|c||}{Emoción} & 
				\multicolumn{2}{|c|}{TESS y SAVEE} \\
				\hline
				& 
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}\\
				\hline
				asco 		&  0.96 &  0.91 \\
				felicidad 	&  0.94 &  0.91 \\
				sorpresa 	&  0.96 &  0.94 \\
				tristeza 	&  0.99 &  0.94 \\
				miedo 		&  0.95 &  0.92 \\
				enfado 		&  0.75 &  0.85 \\
				neutral 	&  0.89 &  0.93 \\
				\hline
			\end{tabular}
			
			\caption{Prueba 4: Resultados del modelo CNN entrenado con espectogramas MFCC exrtaídos de la combinación de los conjuntos de datos TESS y SAVEE}
			\label{result_Test4}
		\end{center}
	\end{table}
	
	\subsubsection{Prueba 5}
	\paragraph{Entrenamiento}
	En esta prueba el modelo escogido (red CNN bidimensional con salida LSTM) fue entrenada durante 100 épocas con batch de tamaño 32 llegando a un 90.37\% de precisión. 
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.35]{test4_5/savee_tess_lstmcnn2d.png} 
		\caption{Rendimiento del modelo CNN - LSTM usando los datos de SAVEE y TESS}
		\label{fig:lstm-cnn}
	\end{figure}

	Si observamos la figura \ref{fig:lstm-cnn}, al igual que en la prueba 4, en el entrenamiento se alcanzaron valores altos en una época temprana (en la \emph{epoch} 5  pasa de un 78\% a un 80\% de precisión en test), y se estabiliza en torno a la época 65 (90\% ~ 91\%).

	\paragraph{Evaluación}
	Junto con la prueba 4, estas fueron las que mejores resultados reportaron, despejando cualquier duda sobre la eficacia de trabajar con espectrogramas. En la tabla \ref{result_Test5} observamos ciertas curiosidades.
	\begin{itemize}
		\item Se mantiene que el enfado es el que más cuesta reconocer, pero sin embargo es la única emoción cuya F1 es más alta que su precisión. Esto también ocurre en las pruebas anteriores.
		
		\item La que puntúa más alto, es el asco, en lugar de la tristeza como ocurren en las pruebas anteriores, sin embargo podemos ver que tristeza, asco, sorpresa, felicidad y miedo son las que más fácilmente reconoce. 
		
		\item El miedo y el estado neutral, mantienen unos valores muy estables entre la precisión y F1.
	\end{itemize}
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c|| c c | }
				\hline
				\multicolumn{1}{|c||}{Emoción} & 
				\multicolumn{2}{|c|}{TESS y SAVEE} \\
				\hline
				& 
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}\\
				\hline
				asco 		& 1.00 & 0.95 \\
				felicidad 	& 0.98 & 0.93 \\
				sorpresa 	& 0.99 & 0.93 \\
				tristeza 	& 0.96 & 0.90 \\
				miedo 		& 0.92 & 0.92\\
				enfado 		& 0.69  & 0.81 \\
				neutral 	& 0.88 & 0.89\\
				\hline
			\end{tabular}
			
			\caption{Prueba 5: Resultados del modelo CNN-LSTM entrenado con espectogramas MFCC extradídos de la combinación de los conjuntos de datos TESS y SAVEE}
			\label{result_Test5}
		\end{center}
	\end{table}
	
	\section{Evaluación con otros Lenguages}
	En esta segunda parte hablaremos del desarrollo de las pruebas donde los modelos más exitosos de las pruebas anteriores, son validados en idiomas extranjeros.
	Hay que mencionar, que los datos de entrenamiento se preprocesaron exactamente igual que en las pruebas donde sus correspondientes modelos formaron parte (el modelo CNN 1D en la prueba 3.B, el modelo CNN 2D en la prueba 4 y el modelo CNN-LSTM 2D en la prueba 5 ) por lo que carece de interés repetir aquí la misma información. 
	Por la misma razón tampoco se comentará el entrenamiento, que de poco se diferencia de las pruebas ya mencionadas.
	
	\subsection{Pruebas 6, 7 y 8}
	Las pruebas 6, 7 y 8 evaluarán un sistema que es capaz de clasificar en inglés, con la expresión de emociones en alemán usando la base de datos EMO-DB. Aunque la prueba principal era evaluar el mejor modelo resultante de las pruebas anteriores, hemos decidido que sería interesante evaluarlo en aquellos modelos que no dieron tan buen resultado (por encima del 80\% de exactitud como se dijo en el capítulo 3, de otro modo esos resultados podrían ser demasiado aleatorios).
	 
	\paragraph{Datos y preprocesado}

	Tras utilizar técnicas de aumento de datos en EMO-DB, y balancearlo, la distribución entre las clases quedó como se muestra en la tabla \ref{ref:balanceTest678}
	La reducción de las emociones para que las bases de datos casaran, mermó el conjunto de validación a 455 características, y el de entrenamiento por consiguiente a 2364 características.
	

	\begin{comment}
		Ya que los datos de validación procedían de un corpus diferente al de entrenamiento, se eliminaron las emociones "miedo" y "sorpresa" para que los datos fuesen coherentes y las clases se correspondieran entre sí. Por lo que disponíamos de 2364 datos para el entrenamiento y 455 para la validación.\\
		Además EMO-DB presentaba una distribución de los datos bastante irregular, por lo que se procedió a balancearlos:
		\begin{enumerate}
		\item En primer lugar se aplicó aumento de datos (sólo con desplazamiento del sonido), para que en el segundo paso no quedase demasiado reducido.
		\item Después se eliminaron muestras de las clases más numerosas hasta equipararlos.
		\end{enumerate}
		Este balanceo se hizo en la extracción de características en la prueba 6, y en la generación de datos en las pruebas 7 y 8. Tras normalizarlos y dividir los datos y las clases, la distribución de las mismas quedó como muestra la tabla \ref{ref:balanceTest678}.
		
		Tras utilizar técnicas de aumento de datos en EMO-DB, y balancearlo, la distribución entre las clases quedó como se muestra en la tabla \ref{emoPostBal}
		\begin{table}[H]
		\centering
		\begin{center}
		\begin{tabular}{ c |  c |  c |  c }
		Emoción & EMO-DB aum. & EMO-DB balan. \\
		\hline
		asco 		& 138 & 138 		\\
		felicidad 	& 213 & 138 	\\
		tristeza 	& 186 & 138 	\\
		enfado 		& 381 & 138 		\\
		neutral 	& 237 & 138	 	\\
		\hline
		\end{tabular}
		
		\caption{Balance entre las clases pertenecientes a EMOD-DB, usar aumento de datos y balancearlo.}
		\label{emoPostBal}
		\end{center}
		\end{table}
	\end{comment}
	
	
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{ c  c | c  c |c  c }
				\multicolumn{2}{c|}{Prueba 6} &
				\multicolumn{2}{|c|}{Prueba 7} &
				\multicolumn{2}{|c}{Prueba 8} \\
				\hline
				asco 		& 90 & asco 	& 90 & asco 	  & 90\\
				felicidad 	& 91 & felicidad & 91 & felicidad & 91\\
				tristeza 	& 92 & tristeza & 92 & tristeza   & 92\\
				enfado 		& 91 & enfado 	& 91 & enfado 	  & 91\\
				neutral 	& 91 & neutral 	& 91 & neutral 	  & 91\\
				\hline
			\end{tabular}
			
			\caption{Balance entre las clases pertenecientes a EMOD-DB, tras preprocesarlo para usarlo en las correspondientes pruebas.}
			\label{ref:balanceTest678}
		\end{center}
	\end{table}
	
	\paragraph{Evaluación}
	Los resultados en general, fueron bastante pésimos consiguiendo un 27\%, 22\% y 28\% de precisión respectivamente.
	En la tabla \ref{results_TestGerman} se muestran los resultados conseguidos tras haber evaluado los modelos anteriores con el idioma alemán.
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c|| c c |  c c |  c c | }
				\hline
				\multicolumn{1}{|c||}{Emoción} & 
				\multicolumn{2}{|c|}{Modelo CNN 1D}&
				\multicolumn{2}{|c|}{Modelo CNN 2D} &
				\multicolumn{2}{|c|}{Modelo CNN-LSTM} \\
				
				\hline
				& 
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}&
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}&
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}\\
				\hline
				
				asco 		& 0.25 & 0.20 & 0.17 & 0.10 & 0.17 & 0.19 \\
				felicidad 	& 0.57 & 0.56 & 0.32 & 0.11 & 0.49 & 0.28 \\
				tristeza 	& 0.49 & 0.32 & 0.07 & 0.08 & 0.27 & 0.23 \\
				enfado 		& 0.16 & 0.23 & 0.18 & 0.14 & 0.30 & 0.26\\
				neutral 	& 0.27 & 0.16 & 0.32 & 0.46 & 0.31 & 0.40\\
				\hline
			\end{tabular}
			
			\caption{Resultados al evaluar los mejores modelos con el idioma alemán}
			\label{results_TestGerman}
		\end{center}
	\end{table}

	Desgraciadamente, no se pudo encontrar ninguna relación en el reconocimiento de emociones entre los modelos, así como en la sección anterior vimos que la emoción más difícil de distinguir era el asco, aquí difícilmente se ve un patrón.\\
	En la prueba 6 con el Modelo CNN 1D, el más difícil de clasificar es el estado neutral, mientras que en el Modelo CNN 2D el que más le cuesta es la tristeza, y en el Modelo CNN-LSTM, el asco.
	
	\subsection{Prueba 9, 10 y 11}
	Este conjunto de pruebas están dedicadas a la evaluación de los modelos que puntuaron más alto en la sección \ref{cap:4ModeloOptimo}, en el idioma francés.
	\paragraph{Datos y preprocesado}
	Una vez se preprocesaron los datos como se especifica en el capítulo 4, el balance del conjunto de entrenamiento quedó como se muestra en la tabla \ref{ref:balanceTest91011}.
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{ c  c | c  c |c  c }
				\multicolumn{2}{c|}{Prueba 9} &
				\multicolumn{2}{|c|}{Prueba 10} &
				\multicolumn{2}{|c}{Prueba 11} \\
				\hline
				asco 		& 107 & asco 		& 107 & asco 	  & 107	\\
				felicidad 	& 107 & felicidad 	& 105 & felicidad & 105	\\
				tristeza 	& 107 & tristeza 	& 108 & tristeza  & 108	\\
				enfado 		& 107 & enfado 		& 108 & enfado 	  & 108	\\
				neutral 	& 107 & neutral 	& 106 & neutral   & 106	\\
				sorpresa 	& 106 & sorpresa 	& 108 & sorpresa  & 108 \\
				miedo 		& 107 & miedo		& 106 & miedo 	  & 106 \\
				\hline
			\end{tabular}
			
			\caption{Balance entre las clases pertenecientes a CAFFE, tras preprocesarlo para usarlo en las correspondientes pruebas.}
			\label{ref:balanceTest91011}
		\end{center}
	\end{table}
	En las tres pruebas se extrajeron 13 características MFCC, con la diferencia de que en las pruebas 10 y 11, se generaron los espectrogramas a partir de esas características.
	
	\paragraph{Evaluación}
	Los resultados de la clasificación de cada emoción por cada uno de los modelos se muestra en la tabla \ref{results_TestFrench}.
	
	\begin{table}[H]
		\centering
		\begin{center}
			\begin{tabular}{| c|| c c |  c c |  c c | }
				\hline
				\multicolumn{1}{|c||}{Emoción} & 
				\multicolumn{2}{|c|}{Modelo CNN 1D}&
				\multicolumn{2}{|c|}{Modelo CNN 2D} &
				\multicolumn{2}{|c|}{Modelo CNN-LSTM} \\
				
				\hline
				& 
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}&
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}&
				\multicolumn{1}{|c|}{Accuracy}&\multicolumn{1}{|c|}{F1}\\
				\hline
				
				asco 		& 0.00 & 0.00 & 0.15 & 0.20 & 0.21 & 0.22\\
				felicidad 	& 0.00 & 0.00 & 0.17 & 0.20 & 0.18 & 0.25 \\
				tristeza 	& 0.28 & 0.18 & 0.23 & 0.10 & 0.21 & 0.11 \\
				enfado 		& 0.14 & 0.23 & 0.19 & 0.22 & 0.20 & 0.26 \\
				neutral 	& 0.00 & 0.00 & 0.17 & 0.20 & 0.35 & 0.11 \\
				sorpresa 	& 0.00 & 0.00 & 0.11 & 0.03 & 0.36 & 0.24 \\
				miedo 		& 0.09 & 0.07 & 0.20 & 0.09 & 0.11 & 0.10 \\
				\hline
			\end{tabular}
			
			\caption{Resultados al evaluar los mejores modelos con el idioma francés}
			\label{results_TestFrench}
		\end{center}
	\end{table}

	Aunque los resultados son realmente pobres, encaja con las expectativas previas, en las que los modelos evaluados en este idioma tendrían un peor desempeño. Por otro lado vuelve a cumplirse, que el Modelo basado en redes convolucionales unidimensionales (Modelo CNN 1D) tiene una precisión más baja en general, en comparación con el enfoque que trabaja con espectrogramas (Modelo CNN 2D y Modelo CNN-LSTM). 


		
		
		
		
		
		
		

	\printbibliography
	
\end{document}