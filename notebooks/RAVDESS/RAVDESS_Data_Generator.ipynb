{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RAVDESS_Data_Generator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/G9/q6ji26L1//EdYIuJw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0Rtk88cTg1wL"},"source":["# **RAVDESS LECTURA DE DATOS**\n","\n","Este notebook contiene una serie de métodos cuyo objetivo es la generación de datos que se usarán en el entrenamiento de las redes.\n","\n","Proyecto Fin de Máster\n","</br>\n","Luisa Sanchez Avivar\n","    _luisasanavi@gmail.com_"]},{"cell_type":"code","metadata":{"id":"P8zRE5Eogr4o","executionInfo":{"status":"ok","timestamp":1623153459855,"user_tz":-120,"elapsed":247,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["# IMPORT LIBRARIES\n","\n","# Processing\n","import librosa\n","import librosa.display\n","import numpy as np\n","import random\n","from tqdm import tqdm\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import IPython.display as ipd\n","\n","# Files\n","import os\n","import joblib\n","import pickle\n","\n","# Machine Learning\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.metrics import confusion_matrix\n","import keras\n","from keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from keras.models import Sequential, Model, model_from_json\n","from keras.layers import Dense, Embedding, LSTM\n","from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n","from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n","import tensorflow as tf\n","\n","# ####### TEST ####### \n","# Scipy\n","from scipy import signal\n","from scipy.io import wavfile"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BGm6jbhhESr","executionInfo":{"status":"ok","timestamp":1623153462312,"user_tz":-120,"elapsed":238,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["AUDIO_DATA_PATH = 'data/'\n","GPATH = '/content/drive/My Drive/Master/Asignaturas/2 Cuatrimestre/Proyecto/Code/'\n","LPATH_DATA = 'SpeechEmotionRecognition/data/procesed/' \n","LPATH_IMG = 'spectrograms/' \n","SAMPLE_FILE = \"03-01-01-01-01-01-01.wav\"\n","\n","# Maps\n","EMOTION_MAP = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}\n","INTENSITY_MAP = {1:'normal', 2:'strong'}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NwoOELdmhJs4","executionInfo":{"status":"ok","timestamp":1623154155483,"user_tz":-120,"elapsed":260,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"cbbf2bfd-171a-42a0-9580-540cbe4c1a05"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bvNq1Ym_qd5o","executionInfo":{"status":"ok","timestamp":1623156665455,"user_tz":-120,"elapsed":238,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["import sys  \n","sys.path.insert(0, GPATH + 'SpeechEmotionRecognition')"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"LKqOx2bIsYNn","executionInfo":{"status":"error","timestamp":1623158732862,"user_tz":-120,"elapsed":249,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"7cdd6fa7-7131-4115-878a-1ba72f129a8f"},"source":["# from src.MEL import MEL\n","import src\n","# a = src.SpeechFeatures\n","# a.SpeechFeatures\n","mfcc = src.MFCC"],"execution_count":80,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-878c31881e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# a = src.SpeechFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# a.SpeechFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMFCC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'src' has no attribute 'MFCC'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POBUbJx3hNpP","executionInfo":{"status":"ok","timestamp":1623141150349,"user_tz":-120,"elapsed":232,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"3226b517-74df-4f14-d9a5-1e5523e2f55f"},"source":["dir_list = os.listdir(GPATH + AUDIO_DATA_PATH)\n","dir_list.sort()\n","\n","print(dir_list)\n","\n","emotion = []\n","gender = []\n","intensity = []\n","path = []\n","\n","# Extraemos de cada archivo de sonido sus datos\n","for dir in dir_list:\n","  path_dir = os.listdir(GPATH + AUDIO_DATA_PATH + dir) # todos los archivos de audios asociados a un directorio\n","  for filepath in path_dir:\n","    info_vector = filepath.split('.')[0].split('-')\n","    n_emotion = int(info_vector[2])\n","    n_gender = int(info_vector[6])\n","    n_intensity = int(info_vector[3])\n","    str_path = GPATH + AUDIO_DATA_PATH + dir + '/' + str(filepath)\n","    path.append(str_path)\n","    emotion.append(n_emotion)\n","    intensity.append(n_intensity)\n","    if n_gender%2 == 0:\n","      gender.append('female')\n","    else:\n","      gender.append('male')\n","\n","# Construimos el data frame\n","EnglishSpeech_df = pd.DataFrame(columns=['emotion', 'gender', 'intensity', 'path'])\n","EnglishSpeech_df['emotion'] = emotion\n","EnglishSpeech_df['gender'] = gender\n","EnglishSpeech_df['intensity'] = intensity\n","EnglishSpeech_df['path'] = path\n","EnglishSpeech_df['emotion'] = EnglishSpeech_df['emotion'].map(EMOTION_MAP) \n","EnglishSpeech_df['intensity'] = EnglishSpeech_df['intensity'].map(INTENSITY_MAP)\n","\n","\n","print(\"Size of the dataset: {} \\n\".format(len(EnglishSpeech_df)))\n","class_distribution = EnglishSpeech_df['emotion'].value_counts()\n","print(class_distribution)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05', 'Actor_06', 'Actor_07', 'Actor_08', 'Actor_09', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_13', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_20', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_24']\n","Size of the dataset: 1440 \n","\n","happy       192\n","fear        192\n","surprise    192\n","calm        192\n","disgust     192\n","angry       192\n","sad         192\n","neutral      96\n","Name: emotion, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wZACy84OWUjI","executionInfo":{"status":"ok","timestamp":1623161124511,"user_tz":-120,"elapsed":26411,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["# Leemos los archivos del directorio con los datos aumentados\n","LPATH_AUGMENTED = GPATH  + 'RAVDESS/augmented/'\n","\n","dir_list = os.listdir(LPATH_AUGMENTED)\n","dir_list.sort()\n","emotion = []\n","path = []\n","\n","for dir in dir_list:\n","  path_dir = os.listdir(GPATH + 'RAVDESS/augmented/' + dir) \n","  for filepath in path_dir:\n","    str_path = LPATH_AUGMENTED + dir + '/' + str(filepath)\n","    emotion.append(dir)\n","    path.append(str_path)\n","\n","RAVDESS_augmented_df = pd.DataFrame(columns=['emotion','path'])\n","RAVDESS_augmented_df['emotion'] = emotion\n","RAVDESS_augmented_df['path'] = path"],"execution_count":87,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QyIftgo5OroR"},"source":["### **OPERACIONES CON TECNICAS DE _DATA AUGMENTATION_**"]},{"cell_type":"code","metadata":{"id":"blehQx_NhV96","executionInfo":{"status":"ok","timestamp":1623161039151,"user_tz":-120,"elapsed":239,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["def white_noise(data):\n","  '''\n","  Agrega ruido blanco a una pista de audio\n","  '''\n","  wn_spectrum = np.random.randn(len(data))\n","  data_wn = data + 0.005*wn_spectrum\n","  return data_wn\n","\n","def shift_audio_sample(data, f_low = -5, f_high = 5, spec = 1):\n","  '''\n","  Desplaza una se;al acustica en un rango de frecuencia\n","  '''\n","  d_range = int(np.random.uniform(low=f_low, high = f_high)*spec) \n","  data_shiftted = np.roll(data, d_range)\n","\n","  return data_shiftted\n","\n","def pitch_shift(data, bins_per_octave=12, pitch_pm = 2):\n","  '''\n","  Modula el tono y modifica la velocidad de una pista de audio\n","  '''\n","  pitch_change =  pitch_pm * 2*(np.random.uniform())   \n","  data_pitch = librosa.effects.pitch_shift(data.astype('float64'),16000, n_steps=pitch_change, bins_per_octave=bins_per_octave)\n","  return data_pitch\n"],"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RsT5qEaXOjMt"},"source":["## **CARACTERISTICAS 1D**"]},{"cell_type":"code","metadata":{"id":"6qmT52KXhnIV","executionInfo":{"status":"ok","timestamp":1623161033068,"user_tz":-120,"elapsed":260,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["def get_features(df, modifier):\n","  '''\n","  Extrae las caracteristicas de un conjunto de pistas de audio a \n","  partir de un dataframe usando librosa\n","\n","  Aguments\n","  ---------\n","    df : dataframe\n","    Dataframe que contiene el path donde se encuentra la pista de audio\n","    modifier: Function\n","    Funcion que modifica los datos\n","\n","  Return\n","  -------\n","   data: np.array \n","   Caracteristicas extraidas\n","\n","  '''\n","  bar_data_range = tqdm(range(len(df)))\n","  data = pd.DataFrame(columns = ['data'])\n","  for index in bar_data_range:\n","    data_features = modifier(df.path[index])\n","    data.loc[index] = [data_features]\n","\n","  return data\n","\n","def get_features_single_file(pathfile):\n","  '''\n","  Extrae las caracteristicas  de una unica pista de audio usando MFCC \n","  a traves de librosa.\n","  \n","  Aguments\n","  ---------\n","    pathfile: str \n","      Path del archivo del que se extraeran las caracteristicas\n","\n","  Return\n","  -------\n","    data_features\n","\n","  '''\n","  X, sample_rate = librosa.load(pathfile, res_type='kaiser_fast')\n","  mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n","  data_features = np.mean(mfcc.T, axis = 0)\n","\n","  return data_features\n","\n","\n","\n","def get_features_white_noise(pathfile):\n","  '''\n","  Extrae las caracteristicas  de una unica pista de audio usando MFCC \n","  a traves de librosa habiendoles aplicado ruido blanco.\n","  \n","  Aguments\n","  ---------\n","    pathfile: str \n","      Path del archivo del que se extraeran las caracteristicas\n","\n","  Return\n","  -------\n","    data_features\n","\n","  '''\n","  X, sample_rate = librosa.load(pathfile, res_type='kaiser_fast')\n","  # X = librosa.core.load(random_sample)[0]\n","\n","  x_data_wn = white_noise(X)\n","  mfcc = librosa.feature.mfcc(y=x_data_wn, sr=sample_rate, n_mfcc=40)\n","  data_features = np.mean(mfcc.T, axis = 0)\n","\n","  return data_features\n","\n","\n","def get_features_shiftted(pathfile):\n","  '''\n","  Extrae las caracteristicas  de una unica pista de audio usando MFCC \n","  a traves de librosa habiendo desplazado las frecuencias perviamente.\n","  \n","  Aguments\n","  ---------\n","    pathfile: str \n","      Path del archivo del que se extraeran las caracteristicas\n","\n","  Return\n","  -------\n","    data_features\n","\n","   '''\n","  X, sample_rate = librosa.load(pathfile, res_type='kaiser_fast')\n","  # X = librosa.core.load(random_sample)[0]\n","\n","  x_data_wn = shift_audio_sample(X)\n","  mfcc = librosa.feature.mfcc(y=x_data_wn, sr=sample_rate, n_mfcc=40)\n","  data_features = np.mean(mfcc.T, axis = 0)\n","\n","  return data_features\n","\n","\n","def get_features_pitch(pathfile):\n","  '''\n","  Aplica modulacion del tono en cada muestra y despues extrae las caracteristicas \n","  usando el algoritmo MFCC\n","  \n","  Aguments\n","  ---------\n","    pathfile: str \n","      Path del archivo del que se extraeran las caracteristicas\n","\n","  Return\n","  -------\n","    data_features\n","\n","  '''\n","  X, sample_rate = librosa.load(pathfile, res_type='kaiser_fast')\n","  # X = librosa.core.load(random_sample)[0]\n","\n","  x_data_wn = pitch_shift(X)\n","  mfcc = librosa.feature.mfcc(y=x_data_wn, sr=sample_rate, n_mfcc=40)\n","  data_features = np.mean(mfcc.T, axis = 0)\n","\n","\n","  return data_features\n","\n"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pWUaln8kPOE"},"source":["## **CARACTERISTICAS 2D: ESPECTOGRAMAS**"]},{"cell_type":"code","metadata":{"id":"osu2Zvu2j44x","executionInfo":{"status":"ok","timestamp":1623161029693,"user_tz":-120,"elapsed":298,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["\n","def get_spectrograms(df, output_path, get_spectrogram):\n","  '''\n","  Genera y almacena espectogramas unas caracteristicas espeficicas\n","  Aguments\n","  ---------\n","  df: DataFrame\n","    dataframe donde estan almacenados los datos\n","\n","  output_path: str\n","    Ruta donde se almacenaran los archivos generados\n","\n","  '''\n","\n","  bar_data_range = tqdm(range(len(df)))\n","  data = pd.DataFrame(columns = ['data'])\n","  \n","  for index in bar_data_range:\n","    get_spectrogram(df.path[index], df.emotion[index] , output_path, index)\n","\n","\n","\n","def save_melspectrogram(pathfile, emotionName, output_path, index):\n","  '''\n","  Genera un espectograma Mel como imagen a partir de un archivo, y lo guarda en una ruta especificada\n","  Aguments\n","  ---------\n","  pathfile: str\n","    Ruta donde se encuentra el archivo.\n","\n","  output_path: str\n","    Ruta donde se guardara la imagen generada.\n","  '''\n","  X, sample_rate = librosa.load(pathfile, res_type='kaiser_fast')\n","  features_melspectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n","  melspectrogram_data = librosa.power_to_db(features_melspectrogram)\n","\n","  # Definimos y convertimos a imagen\n","  fig = plt.figure(figsize=(12,4))\n","  ax = plt.Axes(fig, [0., 0., 1., 1.])\n","  ax.set_axis_off()\n","  fig.add_axes(ax)\n","  librosa.display.specshow(melspectrogram_data, sr=sample_rate, x_axis='time', y_axis='mel')\n","\n","  filename = output_path + emotionName + \"/ravdess_mel_\"+ str(index)+\".jpg\"\n","  if not os.path.exists(output_path + emotionName):\n","    os.makedirs(output_path + emotionName)\n","\n","  plt.savefig(filename, bbox_inches='tight', transparent=True, pad_inches=-0.05)\n","  plt.close()\n","\n","\n","def save_mfccspectrograma(pathfile, emotionName, output_path, index):\n","  '''\n","  Genera un espectograma MFCC como imagen a partir de un archivo, y lo guarda en una ruta especificada\n","  Aguments\n","  ---------\n","  pathfile: str\n","    Ruta donde se encuentra el archivo.\n","\n","  output_path: str\n","    Ruta donde se guardara la imagen generada.\n","  '''\n","  X, sample_rate = librosa.load(pathfile, res_type='kaiser_fast')\n","  features_mfccspectrogram = librosa.feature.mfcc(X, sr=sample_rate, n_mfcc=20)\n","  fig = plt.figure(figsize=(12,4))\n","  ax = plt.Axes(fig, [0., 0., 1., 1.])\n","  ax.set_axis_off()\n","  fig.add_axes(ax)\n","  librosa.display.specshow(features_mfccspectrogram, sr=sample_rate, x_axis='time', y_axis='mel')\n","\n","  filename = output_path + emotionName + \"/ravdess_mfccspectrogram_\" + str(index)+\".jpg\"\n","  if not os.path.exists(output_path + emotionName):\n","    os.makedirs(output_path + emotionName)\n","\n","  plt.savefig(filename, bbox_inches='tight', transparent=True, pad_inches=-0.05)\n","  plt.close()\n","\n","\n"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvW0PEFfh6HL","executionInfo":{"status":"ok","timestamp":1623161027014,"user_tz":-120,"elapsed":235,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["def concat_features(*features):\n","  '''\n","  Concatena varios arrays de caracteristicas devolviendo la combinacion de todos ellos\n","\n","  '''\n","  features_list = []\n","  for feature in features:\n","    # Cada valor es una caracteristica\n","    feature_df = pd.DataFrame(feature['data'].values.tolist())\n","    # Concateno las columnas genero y emocion para poder dividirlo mas tarde\n","    feature_spec = pd.concat((feature_df, EnglishSpeech_df['gender'], EnglishSpeech_df['emotion']), axis = 1)\n","    # Elimino filas vacias\n","    feature_spec = feature_spec.fillna(0)\n","    # Añado a la lista\n","    features_list.append(feature_spec)\n","  \n","  features_complete_df = pd.concat(features_list, ignore_index = True)\n","  return shuffle(features_complete_df)\n","\n","\n","def read_features():\n","  '''\n","  Lee las independientemente las caracteristicas de cada set \n","  '''\n","  # Leemos las caracteristicas estandar (sin data augmentation)\n","  features_standard = get_features(EnglishSpeech_df, get_features_single_file)\n","  try:\n","    pickle.dump(features_standard, open(GPATH + LPATH_DATA + 'features_standard_RAVDESS.pkl', 'wb'))\n","  except Exception as ex:\n","    print(ex)\n","  print(\"Standard features into file\")\n","  # Leemos para Ruido Blanco\n","  features_wn = get_features(EnglishSpeech_df, get_features_white_noise)\n","  try:\n","    pickle.dump(features_wn, open(GPATH + LPATH_DATA + 'features_wn_RAVDESS.pkl', 'wb'))\n","  except Exception as ex:\n","    print(ex)\n","  print(\"White Noise features into file\")\n","\n","  # Leemos para Desplazamiento del Sonido\n","  features_shiftted = get_features(EnglishSpeech_df, get_features_shiftted)\n","  try:\n","    pickle.dump(features_shiftted, open(GPATH + LPATH_DATA + 'features_shiftted_RAVDESS.pkl', 'wb'))\n","  except Exception as ex:\n","    print(ex)\n","  print(\"Shiftted into file\")\n","\n","  # Leemos para Modificacion del Tono\n","  features_pitch = get_features(EnglishSpeech_df, get_features_pitch)\n","  try:\n","    pickle.dump(features_pitch, open(GPATH + LPATH_DATA + 'features_pitch_RAVDESS.pkl', 'wb'))\n","  except Exception as ex:\n","    print(ex)\n","  print(\"Pitch Tunning features into file\")\n","\n","  return features_standard, features_wn, features_shiftted, features_pitch\n","  "],"execution_count":82,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YDiMjua88BRx"},"source":["## **GENERACION DE DATOS**"]},{"cell_type":"markdown","metadata":{"id":"KDQFIYxJb7HD"},"source":["### **ESPECTOGRAMAS DE MEL**"]},{"cell_type":"code","metadata":{"id":"rT4l7-KQjLLX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623079548556,"user_tz":-120,"elapsed":694863,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"3a264717-9cf3-4423-999a-2defdb806184"},"source":["melpath = GPATH + LPATH_IMG + 'mel/'\n","print(melpath)\n","# get_spectrograms(EnglishSpeech_df, melpath , save_melspectrogram)\n","\n","get_spectrograms(RAVDESS_augmented_df, melpath , save_melspectrogram)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/1440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["/content/drive/My Drive/Master/Asignaturas/2 Cuatrimestre/Proyecto/Code/SpeechEmotionRecognition/data/spectrograms/mel/\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1440/1440 [11:34<00:00,  2.07it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7BJsXOFacGgu"},"source":["### **ESPECTOGRAMAS MFCC**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":491},"id":"PG3sivHmcGr_","executionInfo":{"status":"error","timestamp":1623162573472,"user_tz":-120,"elapsed":1448965,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"963c26e2-1608-4e67-a76e-11fc5db74686"},"source":["# get_spectrograms(EnglishSpeech_df, GPATH + LPATH_IMG + 'mfcc/', save_mfccspectrograma) \n","  \n","get_spectrograms(RAVDESS_augmented_df, GPATH + LPATH_IMG + 'mfcc/', save_mfccspectrograma) "],"execution_count":88,"outputs":[{"output_type":"stream","text":[" 14%|█▍        | 1994/14400 [24:07<2:34:53,  1.33it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n","  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"],"name":"stderr"},{"output_type":"error","ename":"EOFError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error opening '/content/drive/My Drive/Master/Asignaturas/2 Cuatrimestre/Proyecto/Code/RAVDESS/augmented/calm/augmented_pitch_04_0729.wav': File contains data in an unknown format.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-88-86d9e0974809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get_spectrograms(EnglishSpeech_df, GPATH + LPATH_IMG + 'mfcc/', save_mfccspectrograma)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_spectrograms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAVDESS_augmented_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mLPATH_IMG\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'mfcc/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_mfccspectrograma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-83-769004050912>\u001b[0m in \u001b[0;36mget_spectrograms\u001b[0;34m(df, output_path, get_spectrogram)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar_data_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mget_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-83-769004050912>\u001b[0m in \u001b[0;36msave_mfccspectrograma\u001b[0;34m(pathfile, emotionName, output_path, index)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mRuta\u001b[0m \u001b[0mdonde\u001b[0m \u001b[0mse\u001b[0m \u001b[0mguardara\u001b[0m \u001b[0mla\u001b[0m \u001b[0mimagen\u001b[0m \u001b[0mgenerada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   '''\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfeatures_mfccspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maifc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0maifc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Return to the beginning of the file to try the next reader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/aifc.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAifc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAifc_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/aifc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/aifc.py\u001b[0m in \u001b[0;36minitfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_soundpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'FORM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file does not start with FORM id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/chunk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrflag\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mEOFError\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"AdzdPSTFcGzl"},"source":["### **ESPECTOGRAMAS ??**"]},{"cell_type":"code","metadata":{"id":"q8Aq7O5WcG61"},"source":[""],"execution_count":null,"outputs":[]}]}