{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RAVDESS_CNN2D.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNN6g0jxOAQhxtnEy0aoEz7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PUgRKUDabFKo"},"source":["# **PRUEBAS 2D**"]},{"cell_type":"code","metadata":{"id":"Ij_u9j9sa9Sh","executionInfo":{"status":"ok","timestamp":1623144030196,"user_tz":-120,"elapsed":5310,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["# IMPORT LIBRARIES\n","\n","# Processing\n","import librosa\n","import librosa.display\n","import numpy as np\n","import random\n","from tqdm import tqdm\n","import cv2\n","from PIL import Image\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import IPython.display as ipd\n","\n","# Files\n","import os\n","import joblib\n","import pickle\n","\n","# Machine Learning\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.metrics import confusion_matrix\n","import keras\n","from keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from keras.models import Sequential, Model, model_from_json\n","from keras.layers import Dense, Embedding, LSTM\n","from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n","from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, AveragePooling1D\n","import tensorflow as tf\n","\n","# ####### TEST ####### \n","# Scipy\n","from scipy import signal\n","from scipy.io import wavfile"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmrW34JZHLzS","executionInfo":{"status":"ok","timestamp":1623144144672,"user_tz":-120,"elapsed":110326,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"cb3392de-87ce-421f-ac72-50cdb85488f1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1fNMwfMObLIr"},"source":["## LECTURA DE DATOS"]},{"cell_type":"code","metadata":{"id":"eDqFVBmmbLQB","executionInfo":{"status":"ok","timestamp":1623144335974,"user_tz":-120,"elapsed":894,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["AUDIO_DATA_PATH = 'data/'\n","GPATH = '/content/drive/My Drive/Master/Asignaturas/2 Cuatrimestre/Proyecto/Code/'\n","LPATH_DATA = 'SpeechEmotionRecognition/data/procesed/' \n","LPATH_IMG = 'spectrograms/' \n","SAMPLE_FILE = \"03-01-01-01-01-01-01.wav\"\n","\n","# Maps\n","EMOTION_MAP = {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fear', 6:'disgust', 7:'surprise'}\n","INTENSITY_MAP = {1:'normal', 2:'strong'}"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cZJuO7KWe5SH"},"source":[""]},{"cell_type":"code","metadata":{"id":"MJw7dfN1fEYo","executionInfo":{"status":"ok","timestamp":1623146346327,"user_tz":-120,"elapsed":397,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["def load_spectograms_dataset(path, mfcc=True, mel=True, classes=EMOTION_MAP, verbose=True):\n","  '''\n","  Devuelve un dataframe con las imágenes generadas que se usarán tanto en el entrenamiento \n","  como en test. Asume que en el path especificado existen esos archivos.\n","  \n","  Arguments:\n","  ----------\n","    path: str\n","      Directorio donde se encuentran las imagenes\n","    mfcc: boolean\n","      Especifica si se añaden los espectogramas MFCC al dataset\n","    mel: boolean\n","      Especifica si se añaden los espectogramas de MEL al dataset\n","    classes: dictionary\n","      Categorias a las que pertenecen las imagenes\n","    verbose: boolean\n","      Especifica si se activan los mensajes mientras se leen las imagenes\n","\n","  Returns:\n","  ----------\n","  '''\n","  list_images = []\n","  labels = []\n","  if mfcc:\n","    mfcc_img, mfcc_lb = load_images(path + \"mfcc/\", EMOTION_MAP)\n","    list_images.extend(mfcc_img)\n","    labels.extend(mfcc_lb)\n","\n","  if mel:\n","    mel_img, mel_lb = load_images(path + \"mel/\", EMOTION_MAP)\n","    list_images.extend(mel_img)\n","    labels.extend(mel_lb)\n","\n","  return list_images, labels\n","\n","def load_images(path, classes=EMOTION_MAP, verbose=True):\n","\n","  '''\n","  Lee las imágenes que se cargarán desde un determinado directorio\n","  Arguments:\n","  ----------\n","    path: str\n","      Directorio donde se encuentran las imagenes\n","    classes: dictionary\n","      Categorias a las que pertenecen las imagenes\n","    verbose: boolean\n","      Especifica si se activan los mensajes mientras se leen las imagenes\n","\n","  Returns:\n","  ----------\n","  '''\n","  list_images = []\n","  labels = []\n","  for index, emotion in classes.items():\n","    emodir = os.path.join(path, emotion)\n","    files = os.listdir(emodir)\n","    images = [file for file in files if file.endswith(\"jpg\")]\n","    if verbose:\n","      print(\"Leídas {} espectogramas pertenecientes a {}\".format(len(images), emotion))\n","    for image_name in images:\n","      image = cv2.imread(os.path.join(emodir, image_name))\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      img_arr = Image.fromarray(image, 'RGB')\n","      resized_img = img_arr.resize((227, 227)) # AlexNet format\n","\n","      list_images.append(np.array(resized_img))\n","      labels.append(index)\n","\n","  return list_images, labels\n","\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFJPK9eVlzxc","executionInfo":{"status":"ok","timestamp":1623148441862,"user_tz":-120,"elapsed":2092098,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"9bd5838c-da45-4639-9874-2e9110938aa0"},"source":["img_spectograms, labels = load_spectograms_dataset(GPATH + LPATH_IMG, True, False)\n","print(\"Se han leído {} imagenes en total\".format(len(img_spectograms) ))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Leídas 96 espectogramas pertenecientes a neutral\n","Leídas 266 espectogramas pertenecientes a calm\n","Leídas 192 espectogramas pertenecientes a happy\n","Leídas 192 espectogramas pertenecientes a sad\n","Leídas 1920 espectogramas pertenecientes a angry\n","Leídas 192 espectogramas pertenecientes a fear\n","Leídas 192 espectogramas pertenecientes a disgust\n","Leídas 192 espectogramas pertenecientes a surprise\n","Se han leído 3242 imagenes en total\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ngs-C6owt0cX"},"source":["## PREPROCESADO DE LOS DATOS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxiA2K58k2oK","executionInfo":{"status":"ok","timestamp":1623148441863,"user_tz":-120,"elapsed":19,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"f90f4d66-f887-482b-81ec-0ae8730163d8"},"source":["images = np.array(img_spectograms)\n","labels = np.array(labels)\n","\n","print(\"Dimensión de los datos: {}\".format(images.shape))\n","print(\"Dimensión de las clases: {}\".format(labels.shape))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Dimensión de los datos: (3242, 227, 227, 3)\n","Dimensión de las clases: (3242,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O2k34WKrTTkA","executionInfo":{"status":"ok","timestamp":1623148444691,"user_tz":-120,"elapsed":1913,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["# Barajamos de manera aleatoria tanto los datos como las clases\n","perm = np.random.permutation(len(images))\n","shuffle_img, shuffle_lb = images[perm], labels[perm]\n","\n","# Normalización para facilitar la convergencia con CNN. Ajustar el recorrido de 0 a 1\n","data_images = shuffle_img.astype(np.float32)\n","labels = labels.astype(np.int32)\n","data_images = data_images/255.0"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WaaX-HVdVcmZ","executionInfo":{"status":"ok","timestamp":1623148445291,"user_tz":-120,"elapsed":604,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"1be34e14-24f4-40d8-f1cc-2b72c91100ef"},"source":["# División de los datos de entrenamiento y test\n","X, X_test, y, y_test = train_test_split(data_images, labels, test_size = 0.2)\n","\n","# Comprobamos la dimensión de cada uno de los conjuntos\n","print(\"Dimension de datos de entrenamiento: {} y de datos de test: {}\".format(X.shape, X_test.shape))\n","print(\"Dimension de las clases entrenamiento: {} y clases de test: {}\".format(y.shape, y_test.shape))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Dimension de datos de entrenamiento: (2593, 227, 227, 3) y de datos de test: (649, 227, 227, 3)\n","Dimension de las clases entrenamiento: (2593,) y clases de test: (649,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlF-6BCwECDE","executionInfo":{"status":"ok","timestamp":1623148445292,"user_tz":-120,"elapsed":14,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}},"outputId":"a8e40c71-32b8-4005-e653-4130f71579f8"},"source":["# One-hot encoding: convierto clases en un array de 0 y 1.\n","\n","yn = to_categorical(y, len(EMOTION_MAP))\n","yn_test = to_categorical(y_test, len(EMOTION_MAP))\n","\n","print(\"La clase {} categorizada: {}\".format(EMOTION_MAP[2], yn[2]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["La clase happy categorizada: [0. 0. 0. 0. 1. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cq-39yGXiEvP","executionInfo":{"status":"ok","timestamp":1623148445293,"user_tz":-120,"elapsed":8,"user":{"displayName":"Luisa Sánchez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtRqDcfvLGMFQUrZnMWjIFyBNK4uoa7Hlh1L2O8w=s64","userId":"11510390526428860545"}}},"source":["def alexNet_model(n_classes, input_shape):\n","  '''\n","  '''\n","  print(\"Modelo con entrada de datos con dimension: {} y {} categorias\".format(input_shape, n_classes))\n","  model = Sequential()\n","  # 1 2D Conv\n","  model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding=\"valid\",activation=\"relu\",input_shape = input_shape ))\n","  model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n","  model.add(BatchNormalization())\n","  # 2 2D Conv\n","  model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n","  model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n","  model.add(BatchNormalization())\n","  # 3 2D Conv\n","  model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n","  # 4 2D Conv\n","  model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n","  # 5 2D Conv\n","  model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n","  model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n","  model.add(BatchNormalization())\n","  # Flatten\n","  model.add(Flatten())\n","  # 1 dense layer\n","  model.add(Dense(4096,input_shape = input_shape, activation=\"relu\"))\n","  model.add(Dropout(0.4))\n","  model.add(BatchNormalization())\n","\n","  #2 dense layer\n","  model.add(Dense(4096,activation=\"relu\"))\n","  model.add(Dropout(0.4))\n","  model.add(BatchNormalization())\n","\n","  #3 dense layer\n","  model.add(Dense(1000,activation=\"relu\"))\n","  model.add(Dropout(0.4))\n","  model.add(BatchNormalization())\n","\n","  # Salida softmax\n","  model.add(Dense(n_classes\n","                  ,activation=\"softmax\"))\n","\n","  return model\n","\n","def CNN_multifeature():\n","  model = Sequential()\n","  model.add(Conv1D(256, 8, padding='same',input_shape=(66,1)))\n","  model.add(Activation('relu'))\n","  model.add(Conv1D(256, 8, padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(Dropout(0.6))\n","  model.add(Conv1D(128, 8, padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(Conv1D(128, 8, padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(Conv1D(128, 8, padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(Conv1D(128, 8, padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(Dropout(0.6))\n","  model.add(Conv1D(64, 8, padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(Conv1D(64, 8, padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(Flatten())\n","  model.add(Dense(4096, activation='relu'))\n","  model.add(Dense(4096, activation='relu'))\n","  model.add(Dropout(0.6))\n","  model.add(Dense(16))\n","  model.add(Activation('softmax'))\n","\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"44hBlekY0lpd"},"source":["alexnet_model = alexNet_model(len(EMOTION_MAP), X.shape[1:])\n","# opt = keras.optimizers.SGD(lr = 0.001, momentum=0.9, decay=0.0)\n","opt = keras.optimizers.Adam(lr=0.0001)\n","# Compilamos el modelo\n","alexnet_model.compile(loss='categorical_crossentropy', \n","              optimizer = opt, \n","              metrics=['accuracy'])\n","\n","# Entrenamos \n","alexnet_model.fit(X, yn, batch_size=16, \n","                        epochs=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Afz-BYaCvX6_"},"source":["cnn_mult"],"execution_count":null,"outputs":[]}]}