
## TODO
* -[ ] Read [this article](https://towardsdatascience.com/how-i-understood-what-features-to-consider-while-training-audio-files-eedfb6e9002b) about feature importance, extract information and write the corresponding conclusion 
* -[ ] Experiments: 
> * -[ ] Ex.1 Result by gender
> * -[ ] Ex.2 Dynamic Value Change
> * -[ ] Ex.3 Pitch tunning
> * -[ ] Ex.4 Shifting
> * -[ ] Ex.5 White noise

## REFERENCES
#### Technical Examples
 * [SER python project](https://towardsdatascience.com/building-a-speech-emotion-recognizer-using-python-4c1c7c89d713): Consigue un 79.3 y explica MEL y MFCC
 * [FrontEnd for Audio Classification - GoogleAI](https://ai.googleblog.com/2021/03/leaf-learnable-frontend-for-audio.html?m=1)
 * [Breaking down the components in SER](https://towardsdatascience.com/automatic-speech-recognition-breaking-down-components-of-speech-85d065061517)

#### ML Organization
* [Organinzing ML project](https://www.jeremyjordan.me/ml-projects-guide/)
* [CookieCutter: Structure dataScience project](https://drivendata.github.io/cookiecutter-data-science/)
* [ML project structure template](https://github.com/ThomasRobertFr/ml-project-structure)
* [create ml app](https://github.com/shreyashankar/create-ml-app)

* [Peer Review](https://www.kdnuggets.com/2020/04/peer-reviewing-data-science-projects.html) A collection of questions to ensure the correctness of results
